API

Vercel =E2=86=92 Project =E2=86=92 Settings =E2=86=92 Environment Variables=
:

i=
ni

Copy code

=

REACT_APP_API_BASE

=3Dht=
tps://<railway-app>.up.railway.app

REACT_APP_DEMO_MODE

=3D

true

Redeploy Vercel.

3) 
Smoke

b=
ash

Copy code

curl -s https://<railway-app>.up.railway.app/heal=
thz
curl -s https://<your-vercel>.vercel.app | 

head

B) Single-URL Vercel (demo endpoint=
s; no websockets)

api/index.js

js

Copy code

const

 se=
rverless =3D 

require

(

'serverless-http'

);

// Ensure backend/app.js exports =
the Express app

const

 app =3D=

require

(

'../backend/app'

)=
;

module

.

exports

=
 =3D 

serverless

(app);

vercel.json

json

Copy code

{

"version"

:

2

,

"builds"

:

[

{

"src"

:

"api/index.js"

,=

"use"

:

"@vercel/node"

}

,

{

"src"

:

"frontend/package.json"

,

"use"

:

"@vercel/static-build"

,

=

"config"

:

{

"distDir"=

:

 =

"build"

}

=

}

]

,

"routes"

:

[

{

"src"

:

"^/api/(.*)$"

,

"dest"

:

"api/index.js"

}

,

{

"src"

:

"^/(.*)$"

,

"dest"

=

:

"frontend/build/$1"

}

]

}

Vercel env (all envs):

NODE_ENV=3Ddemo =C2=B7 DEMO_MOD=
E=3Dtrue =C2=B7 REACT_APP_DEMO_MODE=3Dtrue =C2=B7 JWT_SECRET=3Ddemo-jwt-sec=
ret =C2=B7 CORS_ORIGINS=3Dhttps://<your-vercel>.vercel.app

Go/No-Go gates (2-minute UAT)

/healthz
 returns 200 from the API host.

/api/llm/models/openai
 returns JSON (not HTML).

Demo badge visible; rate-limits ac=
tive.

Ledger verify returns 
{ ok: true }
 on a sample session.

Roundtable dialog opens and return=
s proposals (even if mocked).

60-sec demo script

Open
 your Vercel URL =E2=86=92 call out the =F0=9F=8E=
=AD Demo badge.

Dashboard =E2=86=92 Roundtable
: gather proposals; ment=
ion tamper-evident 
receipt
.

Convo view
: send a message; show 
Trust chips
; run 
Verify
.

Explain governance
: keys server-side, RBAC, /metrics.

Close
: =E2=80=9CTrust First =E2=86=92 then scale what =
resonates=E2=80=9D and the 60-day pilot.

You=E2=80=99ve done the hard part.=
 Choose A (recommended) or B, apply the snippet, and you=E2=80=99re demo-co=
mplete.

=

=

You said:

https://ycq-website-4to4m29lp-ycq.vercel.=
app/#platform

Symbi said:

Thought for 36s

=

nice=
=E2=80=94shared link received. i can=E2=80=99t load that Vercel preview fro=
m here (some preview builds block non-browser fetches), so I=E2=80=99ll giv=
e you a surgical =E2=80=9CPlatform=E2=80=9D section you can drop in 
now
, plus a quick QA checklis=
t to make sure 
#platform
 a=
nchors behave.

Drop-in copy for the 
Platform
 section

H2:
 The yseeku Platform =E2=80=94 
Trust first. Then scale what resonates.

1) What it does (one line)

A compliance-first layer for AI contact centers: cryptographic audit trails=
, fairness-aware QA (AI vs human), and vendor-agnostic guardrails.

2) Three pillars (3=C3=97 short blurbs)

Verifiable Auditability

Append-only, hash-chained ledger with one-click integrity verify and orches=
tration receipts (who/what/why).

Fairness-Aware QA

Separate KPIs for 
AI-only
 vs 
AI=E2=86=94Human
 flows; normalize by case mix so humans aren=E2=80=99t penalized for escal=
ations.

Policy & Guardrails

Thresholds that trigger apology/continuity, escalation, or human approval=
=E2=80=94across OpenAI, Anthropic, and more.

3) How it works (4 steps, horizontal)

Ingest
 =E2=80=93 Capture each turn (prompt/response, m=
odel, config) into a tamper-evident ledger.

Measure
 =E2=80=93 Compute dual-track KPIs (FCR-A vs FC=
R-H), Learning Opportunity Index, Agent Fairness Index.

Govern
 =E2=80=93 Enforce trust thresholds and approval=
s; write receipts explaining decisions.

Resonate
 =E2=80=93 Add Context Capsules (goals, tone, =
constraints) to improve CX 
after
 trust is proven.

4) Metrics we expose (with tiny explainer tooltips)

FCR-A / FCR-H
 =E2=80=94 First-contact resolution (AI-o=
nly vs human-involved).

Escalation =CE=94
 =E2=80=94 Change in escalation rate =
when humans are added.

LOI
 =E2=80=94 Learning Opportunity Index (routine vo