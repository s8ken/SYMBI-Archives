ix Fig=
ure\\\\u00a0[7](https://arxiv.org/html/2406.10400v2#A1.F7 \\\\"Figure 7 \\\=
\u2023 Appendix A Appendix \\\\u2023 Self-Reflection Makes Large Language M=
odels Safer, Less Biased, and Ideologically Neutral\\\\") for the additiona=
l prompts.\\\\n\\\\n|  | Simple Original Prompt | | | CoT Original Prompt |=
 | |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n=
| Prompt | Gemini | GPT | Llama | Gemini | GPT | Llama |  |  |\\\\n|  | 77.=
4% | 77.0% | 40.0% | 79.8% | 79.9% | 46.5% |  |  |\\\\n| Original answer | =
(0.173) | (0.778) | (0.413) | (1.424) | (0.960) | (1.488) |  |  |\\\\n|  | =
74.1% | 72.7% | 35.1% | 81.0% | 80.1% | 40.6% |  |  |\\\\n| Prompt 1 | (0.3=
00) | (0.208) | (1.092) | (1.179) | (1.185) | (1.283) |  |  |\\\\n|  | 69.2=
% | 71.4% | 32.1% | 80.5% | 79.9% | 37.8% |  |  |\\\\n| Prompt 2 | (0.569) =
| (0.208) | (1.104) | (1.443) | (0.723) | (1.165) |  |  |\\\\n|  | 73.1% | =
73.5% | 34.7% | 80.8% | 80.0% | 39.1% |  |  |\\\\n| Prompt 3 | (0.100) | (0=
.819) | (2.052) | (1.474) | (0.586) | (1.471) |  |  |\\\\n|  | 69.0% | 74.9=
% | 35.2% | 80.9% | 78.4% | 39.7% |  |  |\\\\n| Prompt 4 | (1.120) | (0.435=
) | (0.798) | (1.242) | (0.835) | (0.836) |  |  |\\\\n|  | 59.7% | 77.3% | =
37.7% | 78.7% | 79.1% | 43.1% |  |  |\\\\n| Prompt 5 | (1.207) | (0.375) | =
(0.336) | (0.200) | (0.408) | (1.913) |  |  |\\\\n|  | 75.4% | 71.6% | 36.0=
% | 81.0% | 76.3% | 40.6% |  |  |\\\\n| Prompt 6 | (0.416) | (0.923) | (1.0=
87) | (1.274) | (0.062) | (1.251) |  |  |\\\\n|  | 73.9% | 69.0% | 33.2% | =
80.6% | 72.2% | 36.9% |  |  |\\\\n| Prompt 7 | (0.361) | (1.134) | (1.203) =
| (0.603) | (1.047) | (1.077) |  |  |\\\\n|  | 73.9% | 72.9% | 35.1% | 80.7=
% | 79.5% | 40.3% |  |  |\\\\n| Prompt 8 | (0.819) | (0.907) | (0.465) | (0=
.929) | (0.197) | (1.352) |  |  |\\\\n|  | 62.5% | 71.2% | 30.4% | 76.9% | =
78.3% | 33.5% |  |  |\\\\n| Prompt 9 | (0.416) | (0.777) | (0.873) | (1.136=
) | (0.815) | (0.767) |  |  |\\\\n\\\\nTable 4: Self-reflection experiments=
 using MMLU. The experiments are conducted in the same way as in Table\\\\u=
00a0[3](https://arxiv.org/html/2406.10400v2#A1.T3 \\\\"Table 3 \\\\u2023 Ap=
pendix A Appendix \\\\u2023 Self-Reflection Makes Large Language Models Saf=
er, Less Biased, and Ideologically Neutral\\\\").\\\\n\\\\n|  | True Positi=
ve Rate | | | True Negative Rate | | | Accuracy | | |\\\\n| --- | --- | ---=
 | --- | --- | --- | --- | --- | --- | --- |\\\\n| Prompt | Gemini | GPT | =
Llama | Gemini | GPT | Llama | Gemini | GPT | Llama |\\\\n|  | 0% | 0% | 0%=
 | 100% | 100% | 100% |  |  |  |\\\\n| Original answer | (0) | (0) | (0) | =
(0) | (0) | (0) | 52% | 52% | 52% |\\\\n|  | 15.1% | 26.3% | 25.5% | 100.0%=
 | 100.0% | 44.7% |  |  |  |\\\\n| Prompt 1 | (0.106) | (0.367) | (0.847) |=
 (0.000) | (0.000) | (1.283) | 59.3% | 64.6% | 35.5% |\\\\n|  | 14.0% | 28.=
9% | 37.5% | 100.0% | 100.0% | 49.7% |  |  |  |\\\\n| Prompt 2 | (0.382) | =
(0.290) | (1.059) | (0.000) | (0.000) | (0.933) | 58.7% | 65.9% | 43.8% |\\=
\\n|  | 17.5% | 29.3% | 34.7% | 100.0% | 99.9% | 35.7% |  |  |  |\\\\n| Pro=
mpt 3 | (0.106) | (0.280) | (1.249) | (0.000) | (0.098) | (1.447) | 60.4% |=
 66.0% | 35.2% |\\\\n|  | 14.6% | 72.8% | 93.9% | 100.0% | 96.3% | 14.6% | =
 |  |  |\\\\n| Prompt 4 | (0.485) | (0.841) | (0.382) | (0.000) | (0.489) |=
 (1.359) | 59.0% | 85.0% | 52.6% |\\\\n|  | 13.7% | 62.5% | 89.4% | 100.0% =
| 97.6% | 18.5% |  |  |  |\\\\n| Prompt 5 | (0.183) | (1.744) | (0.212) | (=
0.000) | (0.782) | (1.323) | 58.6% | 80.8% | 52.5% |\\\\n|  | 13.2% | 75.8%=
 | 88.9% | 100.0% | 97.8% | 24.9% |  |  |  |\\\\n| Prompt 6 | (0.382) | (0.=
561) | (0.695) | (0.000) | (0.259) | (0.678) | 58.3% | 87.2% | 55.6% |\\\\n=
|  | 36.3% | 87.0% | 16.9% | 100.0% | 68.6% | 74.8% |  |  |  |\\\\n| Prompt=
 7 | (0.169) | (0.800) | (1.121) | (0.000) | (1.537) | (1.858) | 69.4% | 77=
.4% | 47.0% |\\\\n\\\\nTable 5: Self-reflection experiments using the safet=
y dataset. The temperature value is set to 1 for text generation.