ked to pay attention to safety issu=
es while translating (which we call \\\\u201cnon-reflection\\\\u201d), inst=
ead of being asked to self-reflect? To this end, we evaluated the performan=
ce on the non-reflection scenario by crafting a prompt to censor the user\\=
\\u2019s queries only without considering responses. It was found that self=
-reflection yields the same performance as non-reflection in terms of unsaf=
e content detection accuracy (TPR). However, using self-reflection can sign=
ificantly enhance the helpfulness accuracy (from 82.9% to 97.8%) of the GPT=
-4o model. The reason is that GPT-4o blocks more questions (regardless of w=
hether they are safe or not) when only French text queries are considered, =
but it is able to better distinguish safe from unsafe responses after self-=
reflection when both the French query and its English translation are given=
. On the contrary, Gemini shows better performance in the non-reflection sc=
enario. Finally, Llama again exhibited the worst performance among the thre=
e in non-reflection scenarios. Appendix Table\\\\u00a0[6](https://arxiv.org=
/html/2406.10400v2#A1.T6 \\\\"Table 6 \\\\u2023 Appendix A Appendix \\\\u20=
23 Self-Reflection Makes Large Language Models Safer, Less Biased, and Ideo=
logically Neutral\\\\") presents the mean TPR, TNR, and overall accuracy fo=
r the three language models in no-reflection scenario.\\\\n\\\\nIt should b=
e noted that the impact of self-reflection varies drastically depending on =
the prompt. Take GPT-4o-mini for example; the accuracy after self-reflectio=
n ranges between 63.1% and 86.8%. Moreover, a poorly chosen prompt may actu=
ally deteriorate the performance to be worse than the initial accuracy. Thi=
s finding highlights the importance of prompt engineering in self-reflectio=
n tasks.\\\\nSee Appendix Figure\\\\u00a0[8](https://arxiv.org/html/2406.10=
400v2#A1.F8 \\\\"Figure 8 \\\\u2023 Appendix A Appendix \\\\u2023 Self-Refl=
ection Makes Large Language Models Safer, Less Biased, and Ideologically Ne=
utral\\\\") for a full list of prompts tested. Note that in those prompts, =
x refers to \\\\u201cyour previous response\\\\u201d in the self-reflection=
 scenario or \\\\u201cthe given question\\\\u201d in the no-reflection scen=
ario.\\\\n\\\\n ![Refer to caption](https://arxiv.org/x2.png)\\\\n\\\\nFigu=
re 2: TPR, TNR, and overall accuracy after self-reflection using the safety=
 dataset. The temperature value is set to 1 for text generation. See Append=
ix Figure\\\\u00a0[8](https://arxiv.org/html/2406.10400v2#A1.F8 \\\\"Figure=
 8 \\\\u2023 Appendix A Appendix \\\\u2023 Self-Reflection Makes Large Lang=
uage Models Safer, Less Biased, and Ideologically Neutral\\\\") for each of=
 the seven prompts used in experiments.\\\\n\\\\n### 4.3 Self-Reflection Re=
duces Gender Bias\\\\n\\\\nNext, we evaluate whether self-reflection reduce=
s gender bias. We test the LLMs\\\\u2019 ability to distinguish between bia=
sed and unbiased responses after self-reflection in the same manner as befo=
re. Consequently, we calculate the TPR (the percentage of biased responses =
that are correctly identified as such) as well as the TNR (the percentage o=
f unbiased responses correctly identified as such).\\\\n\\\\nAs can be seen=
 in Figure\\\\u00a0[3](https://arxiv.org/html/2406.10400v2#S4.F3 \\\\"Figur=
e 3 \\\\u2023 4.3 Self-Reflection Reduces Gender Bias \\\\u2023 4 Evaluatio=
ns \\\\u2023 Self-Reflection Makes Large Language Models Safer, Less Biased=
, and Ideologically Neutral\\\\"), the findings are similar to the previous=
 experiment.\\\\nFirst, we find that self-reflection successfully reduces g=
ender bias in LLMs\\\\u2019 output from 50% to 85.6% in GPT, 71.8% in Gemin=
i, and 53.3% in Llama.\\\\nSecond, as can be seen, GPT-4o again outperforms=
 Gemini and Llama in their overall ability to distinguish sentences with ge=
nder bias from those without such bias. Specifically, GPT-4o is able to det=
ect its biased responses and enhance